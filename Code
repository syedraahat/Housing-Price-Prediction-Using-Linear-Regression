# Import necessary libraries
import numpy as np  # for numerical operations
import pandas as pd  # for data manipulation and analysis
import matplotlib.pyplot as plt  # for data visualization
import seaborn as sns  # for advanced visualization
from sklearn.model_selection import train_test_split  # for splitting data into train and test sets
from sklearn.linear_model import LinearRegression  # for linear regression model
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score  # for model evaluation

# Load the dataset
df = pd.read_csv('/kaggle/input/housing-prices-dataset/Housing.csv')

# Display the sample size and dataset information
print("Sample Size and Dataset Info:")
print(f"Number of instances (rows): {df.shape[0]}")
print(f"Number of attributes (columns): {df.shape[1]}")

# Display the column names (attributes)
print("\nAttributes of the Dataset:")
print(df.columns.tolist())

# Display the first 5 rows of the dataset
print("\nFirst 5 rows of the dataset:")
print(df.head())

# Preprocess the dataset
# Convert categorical variables into numerical variables using one-hot encoding
# This will handle columns like 'mainroad', 'guestroom', etc.
categorical_columns = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 
                       'airconditioning', 'prefarea', 'furnishingstatus']
df = pd.get_dummies(df, columns=categorical_columns, drop_first=True)  # drop_first to avoid multicollinearity

# Define the feature set (X) and target variable (y)
X = df.drop(['price'], axis=1)  # Features (independent variables)
y = df['price']  # Target variable (price)

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train the Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict the target values on the test set
y_pred = model.predict(X_test)

# Plotting Actual vs Predicted Prices for visual comparison
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred, color='blue', alpha=0.7)  # Scatter plot of actual vs predicted
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)  # Line of perfect prediction
plt.xlabel("Actual Prices")
plt.ylabel("Predicted Prices")
plt.title("Actual vs Predicted Prices")
plt.show()

# Model Evaluation - calculating performance metrics
mse = mean_squared_error(y_test, y_pred)  # Mean Squared Error
mae = mean_absolute_error(y_test, y_pred)  # Mean Absolute Error
r2 = r2_score(y_test, y_pred)  # R-Squared (Goodness of Fit)

# Display the evaluation metrics
print("\nModel Performance Metrics:")
print(f"Mean Squared Error (MSE): {mse:.2f}")  # Lower values are better
print(f"Mean Absolute Error (MAE): {mae:.2f}")  # Lower values are better
print(f"R-Squared (RÂ²): {r2:.2f}")  # Closer to 1.0 is better
